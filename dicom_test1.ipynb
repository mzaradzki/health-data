{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import dicom\n",
    "import pylab\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# defines a utilit function to display array as image\n",
    "import PIL.Image\n",
    "from cStringIO import StringIO\n",
    "import IPython.display\n",
    "def showarray(a, fmt='png'):\n",
    "    a = np.uint8(a)\n",
    "    f = StringIO()\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "    IPython.display.display(IPython.display.Image(data=f.getvalue()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports from : https://www.kaggle.com/gzuidhof/data-science-bowl-2017/full-preprocessing-tutorial/discussion\n",
    "%matplotlib inline\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import scipy.ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import measure, morphology\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# file copied from FastAI mooc\n",
    "import utils\n",
    "import vgg16; reload(vgg16)\n",
    "from vgg16 import Vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patientname = \"0d941a3ad6c889ac451caf89c46cb92a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dicompath = \"../dicom/\" + patientname\n",
    "dicomfiles = [f for f in listdir(dicompath) if isfile(join(dicompath, f)) and f.endswith(\".dcm\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(dicomfiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds = dicom.read_file(dicompath+\"/\"+dicomfiles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert(ds.PatientName == patientname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Order the slices (one slide per dicom file) by SliceLocation\n",
    "def compareBy1(x, y):\n",
    "    delta = x[1] - y[1]\n",
    "    if delta == 0:\n",
    "        return 0\n",
    "    if delta < 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return 1\n",
    "L = [(dcmf, float(dicom.read_file(dicompath+\"/\"+dcmf).SliceLocation)) for dcmf in dicomfiles]\n",
    "orderedL = sorted(L, cmp=compareBy1)\n",
    "orderedL[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DSs = [dicom.read_file(dicompath+\"/\"+f_sl[0]) for f_sl in orderedL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DSs[0].pixel_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw data plot : pixel values needs transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DSs[0].pixel_array.min(), DSs[0].pixel_array.max() # check \"pixel\" data scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "showarray(DSs[0].pixel_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PreProcessing\n",
    "Follow this great tutorial :\n",
    "\n",
    "https://www.kaggle.com/gzuidhof/data-science-bowl-2017/full-preprocessing-tutorial/discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slices = DSs\n",
    "slices.sort(key = lambda x: int(x.ImagePositionPatient[2])) # WARNING : I did another sorting\n",
    "try:\n",
    "    slice_thickness = np.abs(slices[0].ImagePositionPatient[2] - slices[1].ImagePositionPatient[2])\n",
    "except:\n",
    "    slice_thickness = np.abs(slices[0].SliceLocation - slices[1].SliceLocation)\n",
    "    \n",
    "for s in slices:\n",
    "    s.SliceThickness = slice_thickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "slice_thickness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hounsfield Unit (HU)\n",
    "\n",
    "The unit of measurement in CT scans is the Hounsfield Unit (HU), which is a measure of radiodensity. CT scanners are carefully calibrated to accurately measure this.\n",
    "\n",
    "\n",
    "See wikipedia\n",
    "\n",
    "\n",
    "By default however, the returned values are not in this unit. Let's fix this.\n",
    "\n",
    "\n",
    "Some scanners have cylindrical scanning bounds, but the output image is square. The pixels that fall outside of these bounds get the fixed value -2000. The first step is setting these values to 0, which currently corresponds to air. Next, let's go back to HU units, by multiplying with the rescale slope and adding the intercept (which are conveniently stored in the metadata of the scans!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pixels_hu(slices):\n",
    "    image = np.stack([s.pixel_array for s in slices])\n",
    "    # Convert to int16 (from sometimes int16), \n",
    "    # should be possible as values should always be low enough (<32k)\n",
    "    image = image.astype(np.int16)\n",
    "\n",
    "    # Set outside-of-scan pixels to 0\n",
    "    # The intercept is usually -1024, so air is approximately 0\n",
    "    image[image == -2000] = 0\n",
    "    \n",
    "    # Convert to Hounsfield units (HU)\n",
    "    for slice_number in range(len(slices)):\n",
    "        \n",
    "        intercept = slices[slice_number].RescaleIntercept\n",
    "        slope = slices[slice_number].RescaleSlope\n",
    "        \n",
    "        if slope != 1:\n",
    "            image[slice_number] = slope * image[slice_number].astype(np.float64)\n",
    "            image[slice_number] = image[slice_number].astype(np.int16)\n",
    "            \n",
    "        image[slice_number] += np.int16(intercept)\n",
    "    \n",
    "    return np.array(image, dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first_patient = slices\n",
    "first_patient_pixels = get_pixels_hu(first_patient)\n",
    "plt.hist(first_patient_pixels.flatten(), bins=80, color='c')\n",
    "plt.xlabel(\"Hounsfield Units (HU)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "# Show some slice in the middle\n",
    "plt.imshow(first_patient_pixels[80], cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling\n",
    "A scan may have a pixel spacing of [2.5, 0.5, 0.5], which means that the distance between slices is 2.5 millimeters. For a different scan this may be [1.5, 0.725, 0.725], this can be problematic for automatic analysis (e.g. using ConvNets)!\n",
    "A common method of dealing with this is resampling the full dataset to a certain isotropic resolution. If we choose to resample everything to 1mm1mm1mm pixels we can use 3D convnets without worrying about learning zoom/slice thickness invariance.\n",
    "Whilst this may seem like a very simple step, it has quite some edge cases due to rounding. Also, it takes quite a while.\n",
    "Below code worked well for us (and deals with the edge cases):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resample(image, scan, new_spacing=[1,1,1]):\n",
    "    # Determine current pixel spacing\n",
    "    spacing = map(float, ([scan[0].SliceThickness] + scan[0].PixelSpacing))\n",
    "    spacing = np.array(list(spacing))\n",
    "\n",
    "    resize_factor = spacing / new_spacing\n",
    "    new_real_shape = image.shape * resize_factor\n",
    "    new_shape = np.round(new_real_shape)\n",
    "    real_resize_factor = new_shape / image.shape\n",
    "    new_spacing = spacing / real_resize_factor\n",
    "    \n",
    "    image = scipy.ndimage.interpolation.zoom(image, real_resize_factor, mode='nearest')\n",
    "    \n",
    "    return image, new_spacing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that when you apply this, to save the new spacing! Due to rounding this may be slightly off from the desired spacing (above script picks the best possible spacing with rounding).\n",
    "Let's resample our patient's pixels to an isomorphic resolution of 1 by 1 by 1 mm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pix_resampled, spacing = resample(first_patient_pixels, first_patient, [1,1,1])\n",
    "print(\"Shape before resampling\\t\", first_patient_pixels.shape)\n",
    "print(\"Shape after resampling\\t\", pix_resampled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D plotting the scan : VERY VERY SLOW\n",
    "For visualization it is useful to be able to show a 3D image of the scan. Unfortunately, the packages available in this Kaggle docker image is very limited in this sense, so we will use marching cubes to create an approximate mesh for our 3D object, and plot this with matplotlib. Quite slow and ugly, but the best we can do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_3d(image, threshold=-300):\n",
    "    \n",
    "    # Position the scan upright, \n",
    "    # so the head of the patient would be at the top facing the camera\n",
    "    p = image.transpose(2,1,0)\n",
    "    \n",
    "    verts, faces = measure.marching_cubes(p, threshold)\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Fancy indexing: `verts[faces]` to generate a collection of triangles\n",
    "    mesh = Poly3DCollection(verts[faces], alpha=0.1)\n",
    "    face_color = [0.5, 0.5, 1]\n",
    "    mesh.set_facecolor(face_color)\n",
    "    ax.add_collection3d(mesh)\n",
    "\n",
    "    ax.set_xlim(0, p.shape[0])\n",
    "    ax.set_ylim(0, p.shape[1])\n",
    "    ax.set_zlim(0, p.shape[2])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_3d(pix_resampled, 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lung Segmentation\n",
    "In order to reduce the problem space, we can segment the lungs (and usually some tissue around it). The method that me and my student colleagues developed was quite effective.\n",
    "It involves quite a few smart steps. It consists of a series of applications of region growing and morphological operations. In this case, we will use only connected component analysis.\n",
    "The steps:\n",
    "Threshold the image (-320 HU is a good threshold, but it doesn't matter much for this approach)\n",
    "Do connected components, determine label of air around person, fill this with 1s in the binary image\n",
    "Optionally: For every axial slice in the scan, determine the largest solid connected component (the body+air around the person), and set others to 0. This fills the structures in the lungs in the mask.\n",
    "Keep only the largest air pocket (the human body has other pockets of air here and there)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def largest_label_volume(im, bg=-1):\n",
    "    vals, counts = np.unique(im, return_counts=True)\n",
    "\n",
    "    counts = counts[vals != bg]\n",
    "    vals = vals[vals != bg]\n",
    "\n",
    "    if len(counts) > 0:\n",
    "        return vals[np.argmax(counts)]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def segment_lung_mask(image, fill_lung_structures=True):\n",
    "    \n",
    "    # not actually binary, but 1 and 2. \n",
    "    # 0 is treated as background, which we do not want\n",
    "    binary_image = np.array(image > -320, dtype=np.int8)+1\n",
    "    labels = measure.label(binary_image)\n",
    "    \n",
    "    # Pick the pixel in the very corner to determine which label is air.\n",
    "    #   Improvement: Pick multiple background labels from around the patient\n",
    "    #   More resistant to \"trays\" on which the patient lays cutting the air \n",
    "    #   around the person in half\n",
    "    background_label = labels[0,0,0]\n",
    "    \n",
    "    #Fill the air around the person\n",
    "    binary_image[background_label == labels] = 2\n",
    "    \n",
    "    \n",
    "    # Method of filling the lung structures (that is superior to something like \n",
    "    # morphological closing)\n",
    "    if fill_lung_structures:\n",
    "        # For every slice we determine the largest solid structure\n",
    "        for i, axial_slice in enumerate(binary_image):\n",
    "            axial_slice = axial_slice - 1\n",
    "            labeling = measure.label(axial_slice)\n",
    "            l_max = largest_label_volume(labeling, bg=0)\n",
    "            \n",
    "            if l_max is not None: #This slice contains some lung\n",
    "                binary_image[i][labeling != l_max] = 1\n",
    "\n",
    "    \n",
    "    binary_image -= 1 #Make the image actual binary\n",
    "    binary_image = 1-binary_image # Invert it, lungs are now 1\n",
    "    \n",
    "    # Remove other air pockets insided body\n",
    "    labels = measure.label(binary_image, background=0)\n",
    "    l_max = largest_label_volume(labels, bg=0)\n",
    "    if l_max is not None: # There are air pockets\n",
    "        binary_image[labels != l_max] = 0\n",
    " \n",
    "    return binary_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "segmented_lungs = segment_lung_mask(pix_resampled, False)\n",
    "segmented_lungs_fill = segment_lung_mask(pix_resampled, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot_3d(segmented_lungs, 0) # WARNING : currently fails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But there's one thing we can fix, it is probably a good idea to include structures within the lung (as the nodules are solid), we do not only want to air in the lungs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot_3d(segmented_lungs_fill, 0) # WARNING : currently fails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's better. Let's also visualize the difference between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot_3d(segmented_lungs_fill - segmented_lungs, 0) # WARNING : currently fails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anyway, when you want to use this mask, remember to first apply a dilation morphological operation on it (i.e. with a circular kernel). This expands the mask in all directions. The air + structures in the lung alone will not contain all nodules, in particular it will miss those that are stuck to the side of the lung, where they often appear! So expand the mask a little :)\n",
    "This segmentation may fail for some edge cases. It relies on the fact that the air outside the patient is not connected to the air in the lungs. If the patient has a tracheostomy, this will not be the case, I do not know whether this is present in the dataset. Also, particulary noisy images (for instance due to a pacemaker in the image below) this method may also fail. Instead, the second largest air pocket in the body will be segmented. You can recognize this by checking the fraction of image that the mask corresponds to, which will be very small for this case. You can then first apply a morphological closing operation with a kernel a few mm in size to close these holes, after which it should work (or more simply, do not use the mask for this image)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "Our values currently range from -1024 to around 2000. Anything above 400 is not interesting to us, as these are simply bones with different radiodensity. A commonly used set of thresholds in the LUNA16 competition to normalize between are -1000 and 400. Here's some code you can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MIN_BOUND = -1000.0\n",
    "MAX_BOUND = 400.0\n",
    "    \n",
    "def normalize(image):\n",
    "    image = (image - MIN_BOUND) / (MAX_BOUND - MIN_BOUND)\n",
    "    image[image>1] = 1.\n",
    "    image[image<0] = 0.\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero centering\n",
    "As a final preprocessing step, it is advisory to zero center your data so that your mean value is 0. To do this you simply subtract the mean pixel value from all pixels.\n",
    "To determine this mean you simply average all images in the whole dataset. If that sounds like a lot of work, we found this to be around 0.25 in the LUNA16 competition.\n",
    "Warning: Do not zero center with the mean per image (like is done in some kernels on here). The CT scanners are calibrated to return accurate HU measurements. There is no such thing as an image with lower contrast or brightness like in normal pictures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PIXEL_MEAN = 0.25\n",
    "\n",
    "def zero_center(image):\n",
    "    image = image - PIXEL_MEAN\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's next?\n",
    "With these steps your images are ready for consumption by your CNN or other ML method :). You can do all these steps offline (one time and save the result), and I would advise you to do so and let it run overnight as it may take a long time.\n",
    "### IMPORTANT TIP\n",
    "To save storage space, don't do normalization and zero centering beforehand, but do this online (during training, just after loading). If you don't do this yet, your image are int16's, which are smaller than float32s and easier to compress as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Deep Learning model\n",
    "#### Following FastAI course we derive it from pre-trained ImageNet winner "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg = Vgg16()\n",
    "model = vgg.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove top softmax layer as we dont need the 1000 image classification\n",
    "model.pop()\n",
    "# fix the remaining layers as they are\n",
    "for layer in model.layers:\n",
    "    layer.trainable=False\n",
    "# add a 2 category softmax classification for cancer / no-cancer\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
